{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPH6S5QYsgOVusWcmRu+XiK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherlinvarshitha/Generative-AI/blob/main/2303A52266_w_3_ASS_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Find the value of x at which f(x) = 5x^4 + 3x^2 + 10 has minimum value\n",
        "\n"
      ],
      "metadata": {
        "id": "pAZ6YOuADQaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def gradient_descent_1d(alpha=0.01, epsilon=1e-6, max_iter=10000):\n",
        "    def f_prime(x):\n",
        "        return 20 * x**3 + 6 * x  # Derivative of f(x)\n",
        "\n",
        "    x = 0.0  # Initial guess\n",
        "    for _ in range(max_iter):\n",
        "        grad = f_prime(x)\n",
        "        if abs(grad) < epsilon:\n",
        "            break\n",
        "        x -= alpha * grad\n",
        "    return x\n",
        "\n",
        "x_min = gradient_descent_1d()\n",
        "print(f\"Minimum value of f(x) occurs at x = {x_min}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-ijMdEA-LLi",
        "outputId": "ef24a439-8e7e-4af0-d5aa-1e459d8d2678"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of f(x) occurs at x = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Task 2: Find the values of x and y at which g(x, y) = 3x^2 + 5e^(-y) + 10 has minimum value\n"
      ],
      "metadata": {
        "id": "L0YCJ4TEDjgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_2d(alpha=0.01, epsilon=1e-6, max_iter=10000):\n",
        "    def f_prime_x(x):\n",
        "        return 6 * x  # Partial derivative with respect to x\n",
        "\n",
        "    def f_prime_y(y):\n",
        "        return -5 * (2.718281828459045 ** (-y))  # Partial derivative with respect to y\n",
        "\n",
        "    x, y = 0.0, 0.0  # Initial guesses\n",
        "    for _ in range(max_iter):\n",
        "        grad_x = f_prime_x(x)\n",
        "        grad_y = f_prime_y(y)\n",
        "        if abs(grad_x) < epsilon and abs(grad_y) < epsilon:\n",
        "            break\n",
        "        x -= alpha * grad_x\n",
        "        y -= alpha * grad_y\n",
        "    return x, y\n",
        "\n",
        "x_min, y_min = gradient_descent_2d()\n",
        "print(f\"Minimum value of g(x, y) occurs at x = {x_min}, y = {y_min}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsup54pjDd6h",
        "outputId": "bcfa99bd-8714-4e0d-fc9c-c1b050cd9cad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of g(x, y) occurs at x = 0.0, y = 6.216917124174048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Find the value of x at which z(x) = 1 / (1 + e^(-x)) has minimum value\n"
      ],
      "metadata": {
        "id": "29P0o6ocDth4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def gradient_descent_sigmoid(alpha=0.01, epsilon=1e-6, max_iter=10000):\n",
        "    def z_prime(x):\n",
        "        exp_neg_x = 2.718281828459045 ** (-x)\n",
        "        return -exp_neg_x / ((1 + exp_neg_x) ** 2)  # Derivative of sigmoid function\n",
        "\n",
        "    x = 0.0  # Initial guess\n",
        "    for _ in range(max_iter):\n",
        "        grad = z_prime(x)\n",
        "        if abs(grad) < epsilon:\n",
        "            break\n",
        "        x -= alpha * grad\n",
        "    return x\n",
        "\n",
        "x_min_sigmoid = gradient_descent_sigmoid()\n",
        "print(f\"Minimum value of z(x) occurs at x = {x_min_sigmoid}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ08ibETDqJB",
        "outputId": "b2f7c728-aab9-4e38-a427-4a9f3ba90d4e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of z(x) occurs at x = 4.510913300793877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Find the optimal values of M and C for minimizing SE = (ExpectedOutput - PredictedOutput)^2\n"
      ],
      "metadata": {
        "id": "pQ-4POBcD2E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def gradient_descent_linear(alpha=0.01, epsilon=1e-6, max_iter=10000):\n",
        "    expected_outputs = [1, 2, 3, 4, 5]  # Example expected outputs\n",
        "    inputs = [1, 2, 3, 4, 5]  # Example inputs\n",
        "\n",
        "    def predicted_output(m, c, x):\n",
        "        return m * x + c\n",
        "\n",
        "    def se_grad_m(m, c):\n",
        "        return -2 * sum((e - predicted_output(m, c, x)) * x for e, x in zip(expected_outputs, inputs))\n",
        "\n",
        "    def se_grad_c(m, c):\n",
        "        return -2 * sum(e - predicted_output(m, c, x) for e, x in zip(expected_outputs, inputs))\n",
        "\n",
        "    m, c = 0.0, 0.0  # Initial guesses\n",
        "    for _ in range(max_iter):\n",
        "        grad_m = se_grad_m(m, c)\n",
        "        grad_c = se_grad_c(m, c)\n",
        "        if abs(grad_m) < epsilon and abs(grad_c) < epsilon:\n",
        "            break\n",
        "        m -= alpha * grad_m\n",
        "        c -= alpha * grad_c\n",
        "    return m, c\n",
        "\n",
        "m_opt, c_opt = gradient_descent_linear()\n",
        "print(f\"Optimal values are M = {m_opt}, C = {c_opt}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05g3KDQiDzqY",
        "outputId": "3728c424-c8ad-4cc7-a692-a08a7f2643db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal values are M = 0.9999998375829822, C = 5.863769691679814e-07\n"
          ]
        }
      ]
    }
  ]
}